# -*- coding: utf-8 -*-
"""handwritten.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dm8fHqVC0HtNz3PvM7FYaqL1Jdjlodmr
"""





from google.colab import drive
drive.mount('/content/drive')

!mkdir -p /content/drive/MyDrive/Ayaz-ML/data

"""CNN Model"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
import matplotlib.pyplot as plt
import os

# Data preparation
data_gen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2  # Split data for validation
)

# Specify the dataset path
dataset_path = '/content/drive/MyDrive/Ayaz-ML'

# Check if the directory exists
if not os.path.exists(dataset_path):
    raise FileNotFoundError(f"Dataset directory not found: {dataset_path}")

# Loading training set generator
print("Loading training set generator...")
train_gen = data_gen.flow_from_directory(
    dataset_path,
    target_size=(28, 28),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    shuffle=True  # Shuffle to mix classes
)

print("Training set generator loaded.")

# Loading validation set generator
print("Loading validation set generator...")
val_gen = data_gen.flow_from_directory(
    dataset_path,
    target_size=(28, 28),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

print("Validation set generator loaded.")

# Print the number of samples
print(f"Training set size: {train_gen.samples}")
print(f"Validation set size: {val_gen.samples}")

# Building the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(3, activation='softmax')  # 3 classes: Normal, Corrected, Reversal
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
checkpoint = ModelCheckpoint('best_dyslexia_handwriting_model.keras', monitor='val_loss', save_best_only=True)  # Change .h5 to .keras
early_stopping = EarlyStopping(monitor='val_loss', patience=5)

# Train the model
print("Starting model training...")
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10,
    callbacks=[checkpoint, early_stopping],
    verbose=1  # Set verbose to 1 for progress output
)
print("Model training completed.")

# Save the final model
model.save('dyslexia_handwriting_cnn_custom.h5')

# Evaluate the model
val_loss, val_acc = model.evaluate(val_gen)
print(f"Validation Accuracy: {val_acc * 100:.2f}%")

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

pip install easyocr

"""Segmentation of Letter"""

import cv2
import easyocr
import matplotlib.pyplot as plt
import os

# Initialize EasyOCR reader for English characters
reader = easyocr.Reader(['en'])

def preprocess_image(image):
    """Preprocess the image to improve OCR performance."""
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian Blur
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Use adaptive thresholding to create a binary image
    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY_INV, 11, 2)
    return binary

def segment_letters_with_easyocr(image_path, output_folder='segmented_letters'):
    # Read the image using OpenCV
    image = cv2.imread(image_path)

    # Preprocess the image
    processed_image = preprocess_image(image)

    # Use EasyOCR to detect text areas
    results = reader.readtext(processed_image, detail=1, paragraph=False)

    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    letter_images = []
    for idx, (bbox, text, prob) in enumerate(results):
        # Only process single characters
        if len(text) == 1:  # Filter to only include single letters
            # Extract bounding box coordinates
            (top_left, top_right, bottom_right, bottom_left) = bbox
            x_min, y_min = int(top_left[0]), int(top_left[1])
            x_max, y_max = int(bottom_right[0]), int(bottom_right[1])

            # Extract the letter using bounding box coordinates
            letter_image = image[y_min:y_max, x_min:x_max]

            # Save each letter as an individual image
            letter_filename = os.path.join(output_folder, f'letter_{idx}.png')
            cv2.imwrite(letter_filename, letter_image)

            # Store segmented letter images for later use
            letter_images.append(letter_image)

            # Display the segmented letter for verification
            plt.imshow(cv2.cvtColor(letter_image, cv2.COLOR_BGR2RGB))
            plt.title(f'Segmented Letter {idx}: {text}')
            plt.axis('off')  # Hide axis for better visualization
            plt.show()

    print(f"Segmented {len(letter_images)} letters from the image.")
    return letter_images

# Path to the uploaded image
image_path = '/content/drive/MyDrive/Minor_project/handwritten data/CapitalLetters.jpg'

# Run the segmentation function
segmented_letters_with_api = segment_letters_with_easyocr(image_path)

import cv2
import easyocr
import matplotlib.pyplot as plt
import os

# Initialize EasyOCR reader for English characters
reader = easyocr.Reader(['en'])

def segment_letters_with_easyocr(image_path, output_folder='segmented_letters'):
    # Read the image using OpenCV
    image = cv2.imread(image_path)

    # Use EasyOCR to detect text areas
    results = reader.readtext(image, detail=1, paragraph=False)

    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    letter_images = []
    for idx, (bbox, text, prob) in enumerate(results):
        # Process the detected word
        for char in text:
            if char.isupper():  # Only process uppercase characters
                # Calculate the position of the character within the bounding box
                char_index = text.index(char)
                char_x_min = bbox[0][0] + (char_index * (bbox[1][0] - bbox[0][0]) // len(text))
                char_x_max = bbox[0][0] + ((char_index + 1) * (bbox[1][0] - bbox[0][0]) // len(text))

                # Extract bounding box coordinates
                x_min, y_min = int(char_x_min), int(bbox[0][1])
                x_max, y_max = int(char_x_max), int(bbox[2][1])

                # Extract the letter using bounding box coordinates
                letter_image = image[y_min:y_max, x_min:x_max]

                # Save each letter as an individual image
                letter_filename = os.path.join(output_folder, f'letter_{idx}_{char}.png')
                cv2.imwrite(letter_filename, letter_image)

                # Store segmented letter images for later use
                letter_images.append(letter_image)

                # Display the segmented letter for verification
                plt.imshow(cv2.cvtColor(letter_image, cv2.COLOR_BGR2RGB))
                plt.title(f'Segmented Letter {idx}: {char}')
                plt.axis('off')  # Hide axis for better visualization
                plt.show()

    print(f"Segmented {len(letter_images)} letters from the image.")
    return letter_images

# Path to the uploaded image
image_path = '/content/drive/MyDrive/yash_project file/testing_image/image1_page-0001.jpg'  # Replace with your image path

# Run the segmentation function
segmented_letters_with_api = segment_letters_with_easyocr(image_path)

# Print the segmented letters
print("Segmented Letters:")
for letter_img in segmented_letters_with_api:
    plt.imshow(cv2.cvtColor(letter_img, cv2.COLOR_BGR2RGB))
    plt.axis('off')  # Hide axis for better visualization
    plt.show()

#Dyslexia Function
import cv2
import easyocr
import matplotlib.pyplot as plt
import os
import numpy as np
from tensorflow.keras.models import load_model

# Initialize EasyOCR reader for English characters
reader = easyocr.Reader(['en'])

# Load the pre-trained dyslexia detection model
model_path = '/content/drive/MyDrive/yash_project file/best_dyslexia_handwriting_model.keras'  # Update with your model path
model = load_model(model_path)

def preprocess_image(image):
    """Prepares the image for model prediction (resize, normalize)."""
    image_resized = cv2.resize(image, (28, 28))  # Adjust size as per model's input
    if len(image_resized.shape) == 2:
        image_resized = cv2.cvtColor(image_resized, cv2.COLOR_GRAY2BGR)  # Convert to 3 channels
    image_normalized = image_resized / 255.0  # Normalize pixel values
    return np.expand_dims(image_normalized, axis=0)  # Reshape to (1, 28, 28, 3)

def segment_letters_with_easyocr(image_path, output_folder='segmented_letters'):
    """Segments individual letters and returns them along with predictions."""
    # Read the image using OpenCV
    image = cv2.imread(image_path)

    # Use EasyOCR to detect text areas
    results = reader.readtext(image, detail=1, paragraph=False)

    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    letter_images = []
    predictions = []

    for idx, (bbox, text, prob) in enumerate(results):
        for char in text:
            if char.isupper():  # Only process uppercase characters
                # Calculate character's position within bounding box
                char_index = text.index(char)
                char_x_min = bbox[0][0] + (char_index * (bbox[1][0] - bbox[0][0]) // len(text))
                char_x_max = bbox[0][0] + ((char_index + 1) * (bbox[1][0] - bbox[0][0]) // len(text))

                # Extract bounding box coordinates
                x_min, y_min = int(char_x_min), int(bbox[0][1])
                x_max, y_max = int(char_x_max), int(bbox[2][1])

                # Extract the letter using bounding box
                letter_image = image[y_min:y_max, x_min:x_max]

                # Convert to grayscale
                letter_image_gray = cv2.cvtColor(letter_image, cv2.COLOR_BGR2GRAY)

                # Invert colors: background black, text white
                _, letter_image_inverted = cv2.threshold(letter_image_gray, 128, 255, cv2.THRESH_BINARY_INV)

                # Save the letter image
                letter_filename = os.path.join(output_folder, f'letter_{idx}_{char}.png')
                cv2.imwrite(letter_filename, letter_image_inverted)

                # Store letter image and its prediction for summary
                letter_images.append((char, letter_image_inverted))

                # Preprocess the image and predict
                processed_image = preprocess_image(letter_image_inverted)
                prediction = model.predict(processed_image)

                # Append character and prediction
                predictions.append((char, prediction[0][0]))

    print(f"Segmented {len(letter_images)} letters from the image.")
    return letter_images, predictions

def categorize_predictions(predictions):
    """Categorize letters based on the prediction probability."""
    normal, corrected, reversal = [], [], []

    for char, prob in predictions:
        if prob < 0.3:  # Threshold for "Normal"
            normal.append(char)
        elif 0.3 <= prob < 0.7:  # Threshold for "Corrected"
            corrected.append(char)
        else:  # Threshold for "Reversal"
            reversal.append(char)

    return normal, corrected, reversal

def summarize_predictions(letter_images, predictions):
    """Displays each letter with prediction and group results."""
    print("\nFinal Predictions Summary:")
    dyslexic_detected = False

    # Display each letter with its prediction
    for (char, letter_image), (_, prob) in zip(letter_images, predictions):
        label = "Dyslexic Pattern" if prob > 0.5 else "Normal Pattern"

        plt.imshow(letter_image, cmap='gray')
        plt.title(f'Letter: {char} | {label} (Confidence: {prob:.2f})')
        plt.axis('off')  # Hide axis for better visualization
        plt.show()

        if prob > 0.5:
            dyslexic_detected = True

    # Categorize the predictions
    normal, corrected, reversal = categorize_predictions(predictions)

    # Print the grouped results
    print("\nGrouped Results:")
    print(f"Normal: {normal}")
    print(f"Corrected: {corrected}")
    print(f"Reversal: {reversal}")

    # Final summary of dyslexic tendencies
    if dyslexic_detected:
        print("\nOverall: The handwriting shows dyslexic tendencies.")
    else:
        print("\nOverall: The handwriting appears normal.")

# Path to the uploaded image
image_path = '/content/drive/MyDrive/Minor_project/handwritten data/CapitalLetters.jpg'  # Update with your image path

# Run segmentation and collect predictions
letter_images, predictions = segment_letters_with_easyocr(image_path)

# Display final summary with predictions and group results
summarize_predictions(letter_images, predictions)

#Stroke Analaysis

!pip install easyocr
import cv2
import easyocr
import matplotlib.pyplot as plt
import os
import numpy as np

# Initialize EasyOCR reader for English characters
reader = easyocr.Reader(['en'])

def preprocess_image(image):
    """Prepares the image for analysis: resize, normalize."""
    image_resized = cv2.resize(image, (28, 28))  # Adjust size if needed
    if len(image_resized.shape) == 2:
        image_resized = cv2.cvtColor(image_resized, cv2.COLOR_GRAY2BGR)
    image_normalized = image_resized / 255.0
    return image_normalized

def segment_letters_with_easyocr(image_path, output_folder='segmented_letters'):
    """Segments individual letters and prepares them for stroke analysis."""
    # Read the image using OpenCV
    image = cv2.imread(image_path)

    # Use EasyOCR to detect text areas
    results = reader.readtext(image, detail=1, paragraph=False)

    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    letter_images = []
    features_list = []

    for idx, (bbox, text, prob) in enumerate(results):
        for char in text:
            if char.isupper():  # Process only uppercase characters
                # Calculate position of the character within the bounding box
                char_index = text.index(char)
                char_x_min = bbox[0][0] + (char_index * (bbox[1][0] - bbox[0][0]) // len(text))
                char_x_max = bbox[0][0] + ((char_index + 1) * (bbox[1][0] - bbox[0][0]) // len(text))

                # Extract bounding box coordinates
                x_min, y_min = int(char_x_min), int(bbox[0][1])
                x_max, y_max = int(char_x_max), int(bbox[2][1])

                # Extract the letter using bounding box
                letter_image = image[y_min:y_max, x_min:x_max]

                # Convert to grayscale
                letter_image_gray = cv2.cvtColor(letter_image, cv2.COLOR_BGR2GRAY)

                # Invert colors: background black, text white
                _, letter_image_inverted = cv2.threshold(letter_image_gray, 128, 255, cv2.THRESH_BINARY_INV)

                # Save the letter image
                letter_filename = os.path.join(output_folder, f'letter_{idx}_{char}.png')
                cv2.imwrite(letter_filename, letter_image_inverted)

                # Store letter image for summary
                letter_images.append((char, letter_image_inverted))

                # Perform stroke analysis
                features = extract_stroke_features(letter_image_inverted)
                features_list.append((char, features))

    print(f"Segmented {len(letter_images)} letters from the image.")
    return letter_images, features_list

def extract_stroke_features(image):
    """Extracts stroke-related features like aspect ratio, slant, and pixel ratio."""
    # Calculate image dimensions
    height, width = image.shape

    # Aspect ratio
    aspect_ratio = width / height

    # Count black and white pixels
    total_pixels = height * width
    white_pixels = np.sum(image == 255)
    black_pixels = total_pixels - white_pixels
    black_white_ratio = black_pixels / white_pixels if white_pixels != 0 else black_pixels

    # Calculate stroke thickness (mean horizontal projection)
    horizontal_projection = np.sum(image, axis=1) / 255  # Sum across rows
    stroke_thickness = np.mean(horizontal_projection[horizontal_projection > 0])

    # Detect slant using Hough Line Transform
    edges = cv2.Canny(image, 50, 150)
    lines = cv2.HoughLines(edges, 1, np.pi / 180, 50)
    slant_angle = 0
    if lines is not None:
        angles = [np.degrees(line[0][1]) for line in lines]
        slant_angle = np.mean(angles)

    return {
        "Aspect Ratio": aspect_ratio,
        "Black-White Ratio": black_white_ratio,
        "Stroke Thickness": stroke_thickness,
        "Slant Angle": slant_angle
    }

def summarize_stroke_analysis(letter_images, features_list):
    """Displays each letter with its stroke features."""
    print("\nStroke Analysis Summary:")

    for (char, letter_image), (char_feat, features) in zip(letter_images, features_list):
        print(f"\nLetter: {char}")
        for key, value in features.items():
            print(f"  {key}: {value:.2f}")

        # Display the letter image
        plt.imshow(letter_image, cmap='gray')
        plt.title(f'Letter: {char}')
        plt.axis('off')
        plt.show()

image_path = '/content/drive/MyDrive/yash_project file/testing_image/image1_page-0001.jpg'

letter_images, features_list = segment_letters_with_easyocr(image_path)

summarize_stroke_analysis(letter_images, features_list)